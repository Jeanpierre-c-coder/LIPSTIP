{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction d'Embeddings avec ResNet50\n",
    "\n",
    "Ce notebook montre comment utiliser le modèle pré-entraîné **ResNet50** de PyTorch pour extraire les embeddings d'une image. \n",
    "\n",
    "Le script retire la dernière couche fully connected du modèle pour obtenir une représentation vectorielle (embedding) des caractéristiques de l'image. \n",
    "\n",
    "⚠️ **Important** : Assurez-vous que le chemin de l'image est correct. Si le chemin contient des espaces, utilisez des guillemets autour du chemin complet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Pour afficher correctement les images dans le notebook (si besoin)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration du Device et Chargement du Modèle\n",
    "\n",
    "Nous définissons le device global (GPU si disponible, sinon CPU) et chargeons le modèle **ResNet50** pré-entraîné. \n",
    "Le modèle est mis en mode évaluation et déplacé sur le device sélectionné. \n",
    "Ensuite, nous retirons la dernière couche fully connected pour obtenir les embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le device global (GPU si disponible, sinon CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Utilisation du device : {device}\")\n",
    "\n",
    "# Chargement du modèle pré-entraîné ResNet50\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()  # Mode évaluation\n",
    "model.to(device)  # Déplacer le modèle sur le device\n",
    "\n",
    "# Retirer la dernière couche fully connected pour obtenir les embeddings\n",
    "feature_extractor = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "feature_extractor.to(device)  # Déplacer l'extracteur sur le device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Définition du Pipeline de Prétraitement\n",
    "\n",
    "Nous définissons ici un pipeline de prétraitement qui va :\n",
    "- Redimensionner l'image à 256 pixels\n",
    "- Effectuer un crop centré de 224 pixels\n",
    "- Convertir l'image en tenseur\n",
    "- Normaliser l'image avec les moyennes et écarts-types utilisés pour l'entraînement du modèle\n",
    "\n",
    "Ce pipeline permet de préparer l'image pour le modèle ResNet50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),  # Conversion en tensor avec valeurs dans [0, 1]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Définition de la Fonction `get_embedding`\n",
    "\n",
    "La fonction `get_embedding` ouvre une image, applique le prétraitement et extrait les features (embeddings) en passant l'image par le modèle. \n",
    "Le résultat est aplati pour obtenir un vecteur 1D par image.\n",
    "\n",
    "En cas d'erreur lors de l'ouverture de l'image, une exception est levée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(image_path):\n",
    "    \"\"\"\n",
    "    Extrait l'embedding d'une image en utilisant un modèle ResNet50 pré-entraîné.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Chemin vers l'image.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Les features extraites sous forme d'un vecteur plat.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Erreur lors de l'ouverture de l'image {image_path} : {e}\")\n",
    "    \n",
    "    # Appliquer le prétraitement\n",
    "    input_tensor = preprocess(img)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Ajoute la dimension batch\n",
    "    \n",
    "    # Déplacer le batch sur le device approprié\n",
    "    input_batch = input_batch.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        features = feature_extractor(input_batch)\n",
    "    \n",
    "    # Aplatir le résultat pour obtenir un vecteur 1D par image\n",
    "    features = features.view(features.size(0), -1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exemple d'Utilisation\n",
    "\n",
    "Dans cette section, nous utilisons la fonction `get_embedding` sur une image d'exemple. \n",
    "Assurez-vous de remplacer le chemin de l'image par un chemin valide sur votre système. \n",
    "\n",
    "Pour exécuter ce code en dehors d'un notebook, un script Python peut utiliser la clause `if __name__ == '__main__':`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Remplacez ce chemin par le chemin réel de votre image\n",
    "    image_path = r\"C:\\Users\\HP\\Desktop\\LIPSTIP\\Logos_dataset\\earlier_003466547.jpg\"\n",
    "    \n",
    "    embedding = get_embedding(image_path)\n",
    "    print(\"Embedding shape:\", embedding.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
