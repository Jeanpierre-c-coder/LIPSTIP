{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prétraitement d'Images avec OpenCV et PIL/Torchvision\n",
    "\n",
    "Ce notebook présente deux méthodes de prétraitement d'image :\n",
    "\n",
    "- **Avec OpenCV** : L'image est lue, convertie de BGR à RGB, redimensionnée et normalisée.\n",
    "- **Avec PIL et Torchvision** : L'image est chargée avec PIL puis transformée via un pipeline de transformations pour obtenir un tenseur normalisé.\n",
    "\n",
    "Les deux méthodes sont illustrées avec l'affichage du résultat via `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Pour afficher correctement les images dans le notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prétraitement avec OpenCV\n",
    "\n",
    "La fonction `preprocess_image_cv2` effectue les opérations suivantes :\n",
    "\n",
    "- Charge l'image en couleur (format BGR par défaut avec OpenCV).\n",
    "- Convertit l'image de BGR en RGB.\n",
    "- Redimensionne l'image à une taille donnée (par défaut 224x224).\n",
    "- Normalise l'image pour que ses valeurs soient comprises entre 0 et 1.\n",
    "\n",
    "Le résultat est un tableau NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_cv2(image_path, size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Charge et pré-traite l'image avec OpenCV.\n",
    "    L'image est chargée en couleur (BGR), convertie en RGB,\n",
    "    redimensionnée et normalisée (mise à l'échelle entre 0 et 1).\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Chemin vers l'image.\n",
    "        size (tuple): Taille souhaitée de l'image (largeur, hauteur).\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Image prétraitée.\n",
    "    \"\"\"\n",
    "    # Chargement en couleur (BGR)\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"L'image à {image_path} n'a pas pu être chargée.\")\n",
    "    \n",
    "    # Conversion BGR -> RGB\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Redimensionnement\n",
    "    img = cv2.resize(img, size)\n",
    "    \n",
    "    # Normalisation : mise à l'échelle entre 0 et 1\n",
    "    img = img.astype('float32') / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pipeline de Transformation avec Torchvision\n",
    "\n",
    "Ici, nous définissons un pipeline de transformation pour préparer l'image avec PIL :\n",
    "\n",
    "- Redimensionnement à 256 pixels.\n",
    "- Découpage centré à 224 pixels.\n",
    "- Conversion en tenseur (les valeurs sont mises à l'échelle entre 0 et 1).\n",
    "- Normalisation à l'aide de moyennes et écarts-types prédéfinis.\n",
    "\n",
    "Ce pipeline prépare l'image pour l'utilisation avec des modèles de deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_pipeline = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),  # Conversion en tensor avec valeurs dans [0, 1]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prétraitement avec PIL et Torchvision\n",
    "\n",
    "La fonction `preprocess_image_pil` utilise PIL pour charger l'image et applique ensuite le pipeline de transformation défini ci-dessus. \n",
    "\n",
    "Le résultat est un tenseur prétraité, adapté aux modèles de deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_pil(image_path):\n",
    "    \"\"\"\n",
    "    Charge et pré-traite l'image en utilisant PIL et le pipeline Torchvision.\n",
    "    L'image est convertie en format PIL, puis transformée en tensor.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Chemin vers l'image.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Image prétraitée sous forme de tensor.\n",
    "    \"\"\"\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    return transform_pipeline(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exemple d'Utilisation\n",
    "\n",
    "Dans cette section, nous appliquons les deux méthodes de prétraitement sur une image d'exemple. \n",
    "\n",
    "Nous vérifions d'abord que le fichier existe. Ensuite, nous :\n",
    "\n",
    "- Prétraitons l'image avec OpenCV et affichons le résultat.\n",
    "- Prétraitons l'image avec PIL & Torchvision, réarrangeons les dimensions pour l'affichage, puis affichons le résultat.\n",
    "\n",
    "Note : En raison de la normalisation, les valeurs du tenseur peuvent être négatives ou dépasser 1. Pour l'affichage, nous remodulons ces valeurs entre 0 et 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Chemin de l'image (utiliser une chaîne brute pour gérer les espaces et les antislashs)\n",
    "    image_path = r\"C:\\Users\\HP\\Desktop\\LIPSTIP\\Logos_dataset\\earlier_005271598.jpg\"\n",
    "    \n",
    "    # Vérification de l'existence du fichier\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Le fichier n'existe pas : {image_path}\")\n",
    "    else:\n",
    "        # Prétraitement avec OpenCV\n",
    "        try:\n",
    "            processed_img_cv2 = preprocess_image_cv2(image_path)\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(processed_img_cv2)\n",
    "            plt.title(\"Prétraitement avec OpenCV\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(\"Erreur lors du prétraitement avec OpenCV :\", e)\n",
    "\n",
    "        # Prétraitement avec PIL et Torchvision\n",
    "        try:\n",
    "            processed_img_pil = preprocess_image_pil(image_path)\n",
    "            # Réarrangement des dimensions pour l'affichage (C, H, W) -> (H, W, C)\n",
    "            img_np = processed_img_pil.permute(1, 2, 0).numpy()\n",
    "            # Remise à l'échelle pour l'affichage (optionnelle)\n",
    "            img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min())\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(img_np)\n",
    "            plt.title(\"Prétraitement avec PIL & Torchvision\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(\"Erreur lors du prétraitement avec PIL & Torchvision :\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
