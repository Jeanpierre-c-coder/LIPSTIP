{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction d'Embeddings d'Images avec ResNet50 et Affichage d'Images Similaires\n",
    "\n",
    "Ce notebook présente un processus complet pour :\n",
    "\n",
    "- Charger un modèle pré-entraîné (ResNet50) et en extraire les embeddings des images.\n",
    "- Construire le chemin complet des images en évitant la duplication des dossiers.\n",
    "- Charger un DataFrame à partir d'un fichier CSV contenant des chemins d'images.\n",
    "- Extraire les embeddings pour chaque image du DataFrame.\n",
    "- Sélectionner aléatoirement quelques images et calculer les distances (similitude) entre les embeddings.\n",
    "- Afficher en console et graphiquement les images similaires.\n",
    "\n",
    "⚠️ **Note** : Les chemins indiqués dans ce notebook sont adaptés pour un environnement Windows. Adaptez-les si vous utilisez Colab (par exemple, en montant votre Google Drive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "\n",
    "# Pour afficher correctement les images dans le notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fonction pour Construire le Chemin Complet de l'Image\n",
    "\n",
    "Cette fonction permet de construire le chemin complet vers une image en supprimant une éventuelle duplication du dossier de base. Par exemple, si le chemin relatif contient déjà le nom du dossier de base, il sera retiré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_image_path(base_path, relative_path):\n",
    "    \"\"\"\n",
    "    Construit le chemin complet vers l'image en supprimant une éventuelle duplication\n",
    "    du dossier de base (ex. 'Logos_dataset') si présent dans le chemin relatif.\n",
    "    \"\"\"\n",
    "    base_folder = os.path.basename(os.path.normpath(base_path))\n",
    "    if relative_path.startswith(base_folder):\n",
    "        relative_path = relative_path[len(base_folder):].lstrip(\"/\\\\\")\n",
    "    return os.path.join(base_path, relative_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration du Modèle et du Pipeline de Prétraitement\n",
    "\n",
    "Nous utilisons le modèle pré-entraîné **ResNet50** de Torchvision. \n",
    "Le modèle est mis en mode évaluation et déplacé sur le device disponible (GPU si possible). \n",
    "Nous retirons la dernière couche fully connected afin d'obtenir les embeddings de l'image.\n",
    "\n",
    "Le pipeline de prétraitement redimensionne l'image, effectue un crop centré, convertit l'image en tenseur et normalise les valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le device global (GPU si disponible, sinon CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Chargement du modèle pré-entraîné ResNet50\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()  # Mode évaluation\n",
    "model.to(device)  # Déplacer le modèle sur le device\n",
    "\n",
    "# Retirer la dernière couche fully connected pour obtenir les embeddings\n",
    "feature_extractor = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "feature_extractor.to(device)\n",
    "\n",
    "# Définition du pipeline de prétraitement\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),  # Conversion en tensor avec valeurs dans [0, 1]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fonction pour Extraire l'Embedding d'une Image\n",
    "\n",
    "La fonction `get_embedding` ouvre une image, applique le prétraitement, et passe l'image dans le modèle pour obtenir un vecteur d'embedding. \n",
    "Le vecteur est aplati pour obtenir une représentation 1D de l'image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(image_path):\n",
    "    \"\"\"\n",
    "    Extrait l'embedding d'une image en utilisant le modèle ResNet50 pré-entraîné.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Chemin vers l'image.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Vecteur d'embedding aplati.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Erreur lors de l'ouverture de l'image {image_path} : {e}\")\n",
    "    \n",
    "    # Appliquer le prétraitement\n",
    "    input_tensor = preprocess(img)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Ajout de la dimension batch\n",
    "    \n",
    "    # Déplacer le batch sur le device\n",
    "    input_batch = input_batch.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        features = feature_extractor(input_batch)\n",
    "    \n",
    "    # Aplatir le résultat pour obtenir un vecteur 1D\n",
    "    features = features.view(features.size(0), -1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Chargement des Données et Extraction des Embeddings\n",
    "\n",
    "Dans cette section, nous :\n",
    "\n",
    "- Chargeons un DataFrame à partir d'un fichier CSV contenant une colonne `main_mark_image`.\n",
    "- Définissons le chemin de base où se trouvent les images.\n",
    "- Pour chaque image, nous utilisons la fonction `build_image_path` pour construire le chemin complet et la fonction `get_embedding` pour extraire l'embedding.\n",
    "\n",
    "Les embeddings sont stockés dans un dictionnaire associant le chemin relatif de l'image à son embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers le fichier CSV contenant la colonne 'main_mark_image'\n",
    "csv_path = r\"C:\\Users\\HP\\Desktop\\LIPSTIP\\extracted_paths_final_LIPSTIP.csv\"  # Mettez à jour ce chemin si nécessaire\n",
    "\n",
    "# Chargement du DataFrame\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Chemin de base où se trouvent les images\n",
    "base_path = r\"C:\\Users\\HP\\Desktop\\LIPSTIP\\Logos_dataset\"\n",
    "\n",
    "# Extraction des embeddings pour chaque image\n",
    "embeddings = {}\n",
    "for idx, row in df.iterrows():\n",
    "    # Construction du chemin complet de l'image\n",
    "    main_img_path = build_image_path(base_path, row['main_mark_image'])\n",
    "    # Extraction de l'embedding et déplacement sur CPU\n",
    "    emb = get_embedding(main_img_path).cpu().numpy().flatten()\n",
    "    embeddings[row['main_mark_image']] = emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sélection d'Images Aléatoires et Affichage des Images Similaires\n",
    "\n",
    "Nous sélectionnons 3 images aléatoires à partir des embeddings extraits. \n",
    "Pour chaque image sélectionnée, nous calculons la distance euclidienne avec toutes les autres images pour identifier les 5 images les plus proches. \n",
    "\n",
    "Les résultats sont affichés dans la console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection aléatoire de 3 images parmi celles extraites\n",
    "selected_images = random.sample(list(embeddings.keys()), 3)\n",
    "\n",
    "# Affichage en console des 5 images les plus proches pour chaque image sélectionnée\n",
    "for img in selected_images:\n",
    "    distances = {}\n",
    "    for other_img, emb in embeddings.items():\n",
    "        if other_img == img:\n",
    "            continue\n",
    "        dist = np.linalg.norm(embeddings[img] - emb)\n",
    "        distances[other_img] = dist\n",
    "    similar_images = sorted(distances, key=distances.get)[:5]\n",
    "    print(f\"\\nPour l'image {img}, les 5 plus proches sont :\")\n",
    "    for sim_img in similar_images:\n",
    "        print(sim_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Fonction d'Affichage Graphique des Images Similaires\n",
    "\n",
    "Cette fonction affiche l'image de référence et les images similaires sur une même figure. \n",
    "Chaque image est chargée via son chemin complet, puis affichée avec un titre approprié."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_similar_images(reference_image, similar_images):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Affichage de l'image de référence\n",
    "    plt.subplot(1, len(similar_images) + 1, 1)\n",
    "    ref_img = Image.open(build_image_path(base_path, reference_image))\n",
    "    plt.imshow(ref_img)\n",
    "    plt.title(\"Référence\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Affichage des images similaires\n",
    "    for i, sim in enumerate(similar_images):\n",
    "        plt.subplot(1, len(similar_images) + 1, i + 2)\n",
    "        sim_img = Image.open(build_image_path(base_path, sim))\n",
    "        plt.imshow(sim_img)\n",
    "        plt.title(f\"Sim {i+1}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Affichage Graphique des Images Similaires\n",
    "\n",
    "Pour chaque image sélectionnée, nous recalculons les distances et affichons graphiquement l'image de référence et ses 5 images les plus similaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in selected_images:\n",
    "    distances = {}\n",
    "    for other_img, emb in embeddings.items():\n",
    "        if other_img == img:\n",
    "            continue\n",
    "        dist = np.linalg.norm(embeddings[img] - emb)\n",
    "        distances[other_img] = dist\n",
    "    similar_images = sorted(distances, key=distances.get)[:5]\n",
    "    display_similar_images(img, similar_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
